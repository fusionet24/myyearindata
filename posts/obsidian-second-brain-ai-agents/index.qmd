---
title: "Building a Second Brain with Obsidian and AI Agents"
subtitle: "When knowledge graphs meet agentic systems (and why productivity hacks might actually work this time)"
author: "Scott Bell"
date: "2025-01-16"
draft: false
categories:
  - ai
  - agents
  - agentic
  - productivity
  - knowledge-management
  - obsidian
  - llm
---

::: {.callout-tip appearance="simple"}
This content was co-authored with AI assistance. I provided the structure, ideas, and personal experience, while AI helped with organization and prose refinement. See my post on [AI Content Labels](../AI-Content-Labels/index.qmd) for details on my workflow.
:::

## The Productivity Tool Graveyard

Let's be honest if you're reading this, you've probably tried at least three note taking systems in the last few years. The pattern is always the same. You see something new, you try it, then watch it slowly become another abandoned graveyard of good intentions.

Notion. LogSeq. Bear. Apple Notes. OneNote. Back to pen and paper. Then back to digital because your handwriting is terrible (ðŸ‘€) and you can't search paper anyway.

The uncomfortable question lurks beneath all this tool rotation. Are we optimizing our work, or are we just avoiding it? Is building the perfect productivity system a form of productive procrastination?

As a consultant running my own business, I'm always busy. Context switching is the job. I need to remember who said what, which client has which constraints, what decisions were made six months ago. My brain can't hold all of it perfectly. Something has to give.

Late 2023, I watched a video that made me reconsider everything.



{{< video https://www.youtube.com/watch?v=DbsAQSIKQXk 
    title='Hack your brain' 
>}}


## Some context from Stashpad to Obsidian
In [2023, I wrote about Stashpad](../tools-for-consultants/index.qmd) as my note-taking tool of choice. It worked well. Quick capture, good organization, markdown support, timestamping for reviewing historical knowledge. For a year, it was exactly what I needed.

But Stashpad was fundamentally a storage system for thoughts. A filing cabinet with good search. Useful, but passive.

Then I came across [that video](https://www.youtube.com/watch?v=DbsAQSIKQXk) about Obsidian as a thinking environment. Not just notes, but a system for connecting ideas, building knowledge over time, and creating structure from chaos.

What resonated wasn't the feature list. Stashpad stored information. Obsidian promised to help me think.

So I made the switch. Migrated my notes, rebuilt my workflows, learned a new system from scratch. It wasn't instant. It wasn't easy. Some things were objectively worse for the first few weeks. Quick capture was slower. The learning curve was real.

But the difference became clear once I stopped trying to use Obsidian like Stashpad. I wasn't just taking notes anymore. I was building a knowledge system.

I've been using Obsidian for over 2 years now, building a system around daily notes, reflection roll-ups, knowledge graphs, and diagram integration. If you're curious about the specific features I use and what actually works in practice, I've written a companion post: [Why I Use Obsidian](../why-i-use-obsidian/index.qmd).

## Do Productivity Systems Actually Work?

Here's where I need to be honest. I've used Obsidian seriously for about 2 years now. I've built elaborate systems. I've refined workflows. I've spent hours organizing my vault.

And I keep asking myself, Is this making me more productive, or does it just feel like I'm more productive?

The energy redirection problem is real. Every hour spent building the perfect tagging system is an hour not spent doing actual work. Every morning spent organizing yesterday's notes is time not spent on today's priorities. The system itself becomes work.

So does it actually work? 

**What works:** 

- Cognitive offloading is real. Getting information out of my head and into a searchable system creates genuine mental space. I'm not trying to remember everything anymore. I'm trusting the system to remember for me. 

- Context switching costs drop. When I move between projects, I can reload context quickly by reading yesterday's notes instead of spending 20 minutes trying to remember where I was.

- Long-term pattern recognition matters. The weekly and monthly reviews force me to step back and see trends I'd miss in the day-to-day chaos.

**What doesn't work:** 

- The time investment is significant. I spend 30-60 minutes per day on note-taking, organizing, and reviewing. That's real overhead. 

- The system is fragile. Miss a week and everything starts degrading. The value is in the habit, and habits are hard. 

- You can't build the perfect system upfront. I've rebuilt major parts of my vault three times. Each time I thought I had it figured out, I discovered new problems.

**What I've learned:** 

- Build slowly. Don't try to create the perfect system on day one. Start with daily notes. Add features only when you need them. 

- Running a business with multiple side projects creates cognitive overload that's genuinely hard to manage without external support. For my context, this system is essential. For someone with a single focused job? Probably overkill.

::: callout-warning
## The Productivity System Trap

The best productivity system is the one you actually use. If you spend more time organizing notes than creating value from them, you're doing it wrong. I've been there. Multiple times.

The goal isn't a beautiful vault. It's doing better work. If the system doesn't serve that goal, the system is wrong.
:::

And then I started adding AI agents into the mix. That changed everything.

## But it turns out I might have been playing the long game


<blockquote class="twitter-tweet"><p lang="en" dir="ltr">AI agents built into cloud apps will always be sub-par compared to state of the art agents that you can use with Obsidian.<br><br>This is because your Obsidian data is in your control, in plain text formats that are ideal for LLMs to process.<br><br>You can choose to run any of theâ€¦ <a href="https://t.co/pLwxg29m9w">pic.twitter.com/pLwxg29m9w</a></p>&mdash; kepano (@kepano) <a href="https://twitter.com/kepano/status/1969035924152738238?ref_src=twsrc%5Etfw">September 19, 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

*The Creator of Obsidan*

## When AI Agents Tip the Value Equation

Here's where things get interesting. Obsidian as a second brain is useful. Obsidian with AI agents solving problems in your vault? That's empowering.

The core problem with any knowledge management system is overhead. Building it takes time. Maintaining it takes time. Organizing it, tagging it, keeping it current, making sure you can find things later. All of that is necessary work, but it's not the work you're trying to do. It's meta-work.

AI agents solve the ROI problem. They don't replace thinking. They handle the cognitive janitorial work that makes the system sustainable.

I run a local AI server. More control over my data, no API costs for constant queries, and the ability to fine-tune models for my specific workflows. The tradeoff is setup complexity and needing decent hardware. For me, it's worth it.

![Local AI server setup - Another post coming soon](images/local-ai-server.png)

I've built four specialized agents, each solving a specific problem in my vault. Not one general-purpose AI trying to do everything. Four narrow, opinionated, boring agents doing repetitive tasks really well.

This is practical application of the patterns I've been [exploring in my work on agentic systems](../agentic-patterns-right-now-2025/index.qmd). The same ideas about memory systems, retrieval vs retention, and context management apply here. Personal knowledge management is fundamentally about external memory. AI agents just make that external memory system more usable.

::: {.callout-tip collapse="true"}
## Why Local AI?

Running AI models locally gives you control over your data, no API costs for high-frequency queries, and the ability to customize models for your specific workflow. You can fine-tune on your own notes, experiment with prompts without worrying about costs, and keep sensitive client information on your own hardware.

The tradeoff? You need decent hardware (I'm running on a machine with a capable GPU) and some technical setup. There's a learning curve. But for anyone already comfortable with Docker and basic ML concepts, it's manageable. 

This is a great starting video too

{{< video https://www.youtube.com/watch?v=Wjrdr0NU4Sk 
    title='host your ai locally' 
>}}


If local hosting isn't practical, you can use cloud APIs. The patterns are the same. You just trade control for convenience.
:::

Let me break down the specific agents I'm running.

## Four Agents That Actually Solve Problems

These aren't sentient AIs. They're specialized tools that automate specific tasks I used to do manually. Each one solves a real problem I was facing.

### Agent 1: Async Research Agent

**What it does:** Automated research that deposits findings directly into my vault.

I give it research questions or topics I need to understand. "What are the current best practices for multi-region Azure deployments?" or "Who is this company and what should I know before our meeting?" It searches, reads, synthesizes, and creates organized notes in a designated folder for my review.

The process is asynchronous. I queue up research tasks in the morning, and by afternoon there are draft notes waiting. I review them, verify the information, integrate what's useful, and discard what isn't.

**Honest assessment:** The quality varies. Sometimes it nails exactly what I needed. Sometimes it goes off on tangents or misses the point. I always verify the information before trusting it. But it saves hours of initial research grunt work. It's best for breadth, not depth. It gives me enough context to ask better questions and dig deeper where it matters.

### Agent 2: Linting and Metadata Agent

**What it does:** Maintains hygiene in my knowledge vault.

This is the unglamorous agent. It scans for uncataloged notes (no tags, missing metadata, orphaned from the graph). It suggests tags based on content analysis. It identifies broken links. It flags notes I haven't touched in months that might be stale or outdated.

I run it weekly. It generates a report of vault health issues, fixes most auotmatically and I spend 30 minutes cleaning up anything else. Without this agent, the vault would slowly decay into an unsearchable mess.

### Agent 3: Goal Alignment Agent

**What it does:** Keeps my daily work connected to my longer-term objectives.

This is the agent that makes me uncomfortable, which probably means it's working.

I have notes for yearly goals, quarterly priorities, monthly focuses, and weekly targets. This agent reads all of them, analyzes my recent daily notes to see what I've actually been working on, and generates daily reminders about alignment or misalignment.

It's not subtle. "You said Q1 priority was growing your newsletter , but you've spent the last three days listening to podcasts." Sometimes I have good reasons for the mismatch. Often I don't.


Sometimes it's uncomfortably accurate. It requires good goal documentation to be useful. If you don't write down what matters, it can't tell you when you're off track. And not everyone wants this level of tracking. If you're allergic to quantified self concepts, you'll hate this agent.

::: callout-important 
## The Goal Alignment Feedback Loop

**Week 1:** Agent tells me I'm off track.

**Week 2:** I ignore it because I'm "busy." 

**Week 3:** Agent's report shows I've made zero progress on a Q1 priority. 

**Week 4:** I finally adjust.

The system works when you listen to it. If you ignore the signal, it's just noise.
:::

### Agent 4: Agentic RAG for Note Querying

**What it does:** Intelligent retrieval and synthesis across my entire vault.

This is the "search my brain" agent. Natural language queries that go beyond keyword matching. "What have I learned about agentic patterns over the last six months?" It retrieves relevant notes, synthesizes insights across multiple sources, and provides a coherent summary with references.

It's not just search. It's context-aware retrieval. It understands that my note about a meeting might be relevant to a technical question because of a connection I made in a different note.

I also use it for content generation. Writing this post, I queried my vault for everything I've written about productivity, tools, and knowledge management. It pulled together fragments from dozens of notes.


This agent is only as good as the notes you've written. Garbage in, garbage out. If you don't write clear, well-structured notes, the retrieval won't be useful. But if you maintain decent notes, the experience of asking your own knowledge base questions and getting thoughtful answers is remarkable.

As I wrote in my [agentic patterns post](../agentic-patterns-right-now-2025/index.qmd), the shift from retention to retrieval is fundamental. You don't need to remember everything. You need to be able to find and use what you've captured. This agent makes that practical.
Personal Knowledge Management as an Agentic Pattern

Both knowledge graphs and agentic AI have hype problems. Knowledge graphs were supposed to revolutionize how we think. Agentic AI is supposed to replace knowledge workers. Most of the hype is nonsense.

But both deliver real utility to you **a human** when you actually do the work.


**Looking forward:**

This is still early days for agentic/ai augmented personal knowledge management. This is no doubt not my last post on this topic.

It's not a second brain. It's a thinking partner. And with AI agents handling the meta-work, maybe it's finally been worth the investment.